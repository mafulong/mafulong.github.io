---
layout: post
category: DistributedSystem
title: etcd和raft
tags: DistributedSystem
---

# etcd

# raft

不同于Paxos算法直接从分布式一致性问题出发推导出来，Raft算法则是从多副本状态机的角度提出，用于管理多副本状态机的日志复制。Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题：Leader选举（Leader election）、日志同步（Log replication）、安全性（Safety）、日志压缩（Log compaction）、成员变更（Membership change）等。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。

## 状态

Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：

- Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。
- Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。
- Candidate：Leader选举过程中的临时角色。

Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态

## 状态机

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226171751.png" alt="image-20211226171744055" style="zoom:50%;" />

term：任期，比如新的选举任期，即整个集群初始化时，或者新的Leader选举就会开始一个新的选举任期。

Raft算法将时间分为一个个的任期（term），**每一个term的开始都是Leader选举**。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。

## Leader选举

   Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。

   Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：

- 赢得了多数的选票，成功选举为Leader；
- 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；
- 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226171954.png" alt="image-20211226171954920" style="zoom:50%;" />

选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。

Raft保证选举出的Leader上一定具有最新的已提交的日志。

## 日志同步

Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226172121.png" alt="image-20211226172121245" style="zoom:50%;" />

某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。

日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。

- log：Raft系统中的主要工作单元是log     entry。一致性问题可以分解为*replicated log*。log是entry的有序序列，entry包括任何集群更改：添加节点，添加服务，新的键值对等。如果所有成员都同意entry及其顺序，则我们认为log是一致的。
- Quorum：法定人数是来自集群的大多数成员：对于一组大小n，法定人数至少需要(n+1)/2成员。例如，如果在集群中有5个成员，我们至少需要3个节点来形成仲裁。如果由于某些原因无法达到法定数量的节点，则群集将变得*不可用，*并且无法提交新日志。
- Committed Entry:     将条目持久存储在一定数量的节点后，该条目被视为已*提交*。条目被提交后即可应用。

leader扮演的是分布式事务中的协调者，接受客户端的写请求，每次有数据更新的时候产生二段提交。在leader收到数据操作的请求，先不着急更新本地数据，而是生成对应的log，然后把生成log的请求广播给所有的follower。当leader收到超过半数的follower成功写了log的影响，则开始第二阶段的提交：正式写入数据，然后同样广播给follower。

WAL技术+2PC

## 如何提交日志

可以把 Raft 的日志复制理解成一个优化后的二阶段提交

首先，领导者进入第一阶段，通过日志复制（AppendEntries）RPC 消息，将日志项复制到集群其他节点上。接着，如果领导者接收到大多数的“复制成功”响应后，它将日志项应用到它的状态机，并返回成功给客户端。

如果领导者没有接收到大多数的“复制成功”响应，那么就返回错误给客户端。学到这里，有同学可能有这样的疑问了，领导者将日志项应用到它的状态机，怎么没通知跟随者应用日志项呢？

这是 Raft 中的一个优化，领导者不直接发送消息通知其他节点应用指定日志项。因为领导者的日志复制 RPC 消息或心跳消息，包含了当前最大的，将会被提交（Commit）的日志项索引值。

所以通过日志复制 RPC 消息或心跳消息，跟随者就可以知道领导者的日志提交位置信息。因此，当其他节点接受领导者的心跳消息，或者新的日志复制 RPC 消息后，就会将这条日志项应用到它的状态机。

而这个优化，降低了处理客户端请求的延迟，将二阶段提交优化为了一段提交，降低了一半的消息延迟。为了帮你理解，我画了一张过程图，然后再带你走一遍这个过程，这样你可以更加全面地掌握日志复制。

 

通过心跳告诉日志已经提交。

<img src="/Users/mafulong/Library/Application%20Support/typora-user-images/image-20211226172620615.png" alt="image-20211226172620615" style="zoom:50%;" />

1. 接收到客户端请求后，领导者基于客户端请求中的指令，创建一个新日志项，并附加到本地日志中。
2. 领导者通过日志复制     RPC，将新的日志项复制到其他的服务器。
3. 当领导者将日志项，成功复制到大多数的服务器上的时候，领导者会将这条日志项应用到它的状态机中。
4. 领导者将执行的结果返回给客户端。
5. 当跟随者接收到心跳信息，或者新的日志复制     RPC 消息后，如果跟随者发现领导者已经提交了某条日志项，而它还没应用，那么跟随者就将这条日志项应用到本地的状态机中。

## 强一致性的保证：raft的线性一致读方法

### Read Committed Index

Raft leader拥有最新的数据，因此读请求走leader那么leader可以直接返回结果给客户端，但直接从leader状态机读并不能完全确保系统的线性一致性。比如发生网络分区，旧leader处于少数派分区中，此时直接从旧leader的状态机读，则很可能返回过期的数据。所以leader需要在发起读时记录当前的committed Index，然后在后续heartbeat请求中如果能获得多数follower对leadership的确认，那么可以等待committed Index提交到状态机后即可返回结果。记录committed Index是因为当一个节点刚当选 Leader的时候并不知道最新的committed index。

### Follower read

我认为当前etcd就实现的Follower read可能是更有效的一种一致性读的实现方式。读请求可以发给follower，follower先去leader查询最新的committed index，然后等待自身的committed index增长为读请求发生时的leader的committed index，从而保证能从follower中读到最新的数据。



## 安全性保证

![image-20211226173439780](https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226173439.png)

![image-20211226173715304](https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226173715.png)

**选举限制**

在Raft协议中，所有的日志条目都只会从Leader节点往Follower节点写入，且Leader节点上的日志只会增加，绝对不会删除或者覆盖。

这意味着Leader节点必须包含所有已经提交的日志，即能被选举为Leader的节点一定需要包含所有的已经提交的日志。因为日志只会从Leader向Follower传输，所以如果被选举出的Leader缺少已经Commit的日志，那么这些已经提交的日志就会丢失，显然这是不符合要求的。

这就是Leader选举的限制：能被选举成为Leader的节点，一定包含了所有已经提交的日志条目。

 

## 安全性保证总结

- 日志顺序写，保持最新，如果有不一致，会被leader的日志覆盖。
- 选举时只有最新日志的才能参与选举，防止旧的follower当选leader而导致丢信息。
- 防止脑裂，Raft leader拥有最新的数据，因此读请求走leader那么leader可以直接返回结果给客户端，但直接从leader状态机读并不能完全确保系统的线性一致性。比如发生网络分区，旧leader处于少数派分区中，此时直接从旧leader的状态机读，则很可能返回过期的数据。所以leader需要在发起读时记录当前的committed Index，然后在后续heartbeat请求中如果能获得多数follower对leadership的确认，那么可以等待committed Index提交到状态机后即可返回结果。记录committed Index是因为当一个节点刚当选 Leader的时候并不知道最新的committed index。 

