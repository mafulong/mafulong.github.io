---
layout: post
category: DistributedSystem
title: etcd和raft
tags: DistributedSystem
recent_update: true
---

# etcd

# raft

不同于Paxos算法直接从分布式一致性问题出发推导出来，Raft算法则是从多副本状态机的角度提出，用于管理多副本状态机的日志复制。Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题：Leader选举（Leader election）、日志同步（Log replication）、安全性（Safety）、日志压缩（Log compaction）、成员变更（Membership change）等。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。

## 状态

Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：

- Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。
- Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。
- Candidate：Leader选举过程中的临时角色。

Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态



状态机

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226171751.png" alt="image-20211226171744055" style="zoom:50%;" />

term：任期，比如新的选举任期，即整个集群初始化时，或者新的Leader选举就会开始一个新的选举任期。

Raft算法将时间分为一个个的任期（term），**每一个term的开始都是Leader选举**。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。



## Leader选举

   Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。

   Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：

- 赢得了多数的选票，成功选举为Leader；
- 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；
- 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。

如果 Candidate 在一定时间内没有获得足够的投票，那么就会进行一轮新的选举，直到其成为 Leader,或者其他结点成为了新的 Leader，自己变成 Follower。

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226171954.png" alt="image-20211226171954920" style="zoom:50%;" />

选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。

Raft保证选举出的Leader上一定具有最新的已提交的日志。

## 日志同步

Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到超过一半的大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。然后再向followers请求提交数据。

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226172121.png" alt="image-20211226172121245" style="zoom:50%;" />

某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。

日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。

- log：Raft系统中的主要工作单元是log     entry。一致性问题可以分解为*replicated log*。log是entry的有序序列，entry包括任何集群更改：添加节点，添加服务，新的键值对等。如果所有成员都同意entry及其顺序，则我们认为log是一致的。
- Quorum：法定人数是来自集群的大多数成员：对于一组大小n，法定人数至少需要(n+1)/2成员。例如，如果在集群中有5个成员，我们至少需要3个节点来形成仲裁。如果由于某些原因无法达到法定数量的节点，则群集将变得*不可用，*并且无法提交新日志。
- Committed Entry:     将条目持久存储在一定数量的节点后，该条目被视为已*提交*。条目被提交后即可应用。

leader扮演的是分布式事务中的协调者，接受客户端的写请求，每次有数据更新的时候产生二段提交。在leader收到数据操作的请求，先不着急更新本地数据，而是生成对应的log，然后把生成log的请求广播给所有的follower。当leader收到超过半数的follower成功写了log的影响，则开始第二阶段的提交：正式写入数据，然后同样广播给follower。

WAL技术+2PC

### 如何提交日志

可以把 Raft 的日志复制理解成一个优化后的二阶段提交

首先，领导者进入第一阶段，通过日志复制（AppendEntries）RPC 消息，将日志项复制到集群其他节点上。接着，如果领导者接收到大多数的“复制成功”响应后，它将日志项应用到它的状态机，并返回成功给客户端。

如果领导者没有接收到大多数的“复制成功”响应，那么就返回错误给客户端。学到这里，有同学可能有这样的疑问了，领导者将日志项应用到它的状态机，怎么没通知跟随者应用日志项呢？

这是 Raft 中的一个优化，领导者不直接发送消息通知其他节点应用指定日志项。因为领导者的日志复制 RPC 消息或心跳消息，包含了当前最大的，将会被提交（Commit）的日志项索引值。

所以通过日志复制 RPC 消息或心跳消息，跟随者就可以知道领导者的日志提交位置信息。因此，当其他节点接受领导者的心跳消息，或者新的日志复制 RPC 消息后，就会将这条日志项应用到它的状态机。

而这个优化，降低了处理客户端请求的延迟，将二阶段提交优化为了一段提交，降低了一半的消息延迟。为了帮你理解，我画了一张过程图，然后再带你走一遍这个过程，这样你可以更加全面地掌握日志复制。

 

通过心跳告诉日志已经提交。

<img src="https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv5/v5/20220113002527.png" alt="image-20211226172620615" style="zoom:50%;" />

1. 接收到客户端请求后，领导者基于客户端请求中的指令，创建一个新日志项，并附加到本地日志中。
2. 领导者通过日志复制     RPC，将新的日志项复制到其他的服务器。
3. 当领导者将日志项，成功复制到大多数的服务器上的时候，领导者会将这条日志项应用到它的状态机中。
4. 领导者将执行的结果返回给客户端。
5. 当跟随者接收到心跳信息，或者新的日志复制     RPC 消息后，如果跟随者发现领导者已经提交了某条日志项，而它还没应用，那么跟随者就将这条日志项应用到本地的状态机中。



------

## 强一致性读的保证：Raft 的线性一致读方法

Raft 的 Leader 通常拥有最新的数据，因此读请求可以直接通过 Leader 来处理。然而，仅从 Leader 的状态机读取数据并不能完全确保线性一致性。以下情况可能破坏一致性：

- **网络分区**：在某些情况下，旧 Leader 可能位于少数派分区中，仍然接收读请求。这时，直接从旧 Leader 读取数据可能会返回过期的值。

### 1. Read Committed Index

Raft 的 Leader 通常拥有最新的数据，因此读请求可以直接通过 Leader 来处理。然而，仅从 Leader 的状态机读取数据并不能完全确保线性一致性。以下情况可能破坏一致性：

- **网络分区**：在某些情况下，旧 Leader 可能位于少数派分区中，仍然接收读请求。这时，直接从旧 Leader 读取数据可能会返回过期的值。

为了解决这个问题，Leader 在处理线性一致读时，会执行以下步骤：

1. **记录当前的 committed Index**：Leader 在收到读请求时，记录当前的 committed Index（即最新被多数节点确认的日志索引）。
2. **确认领导权**：Leader 在后续的心跳（heartbeat）请求中，向多数派 Follower 确认自己仍然是合法的 Leader。
3. **等待 committed Index 提交到状态机**：在确认领导权后，Leader 等待记录的 committed Index 对应的日志条目已应用到状态机，然后返回结果。

这种方式确保了即使在网络分区或领导权切换等场景下，读请求也能维持线性一致性。

------

### 2. Follower Read

ETCD 中实现了一种更加高效的线性一致性读方法，即 **Follower Read**。它允许读请求通过 Follower 来处理，同时保证强一致性。具体步骤如下：

1. 向 Leader 查询 committed Index：
   - Follower 收到客户端读请求后，先向当前的 Leader 查询最新的 committed Index。
2. 等待自身 committed Index 同步
   - Follower 等待自身的 committed Index 增长到 Leader 返回的值（即读请求发生时 Leader 的 committed Index）。
3. 返回最新数据
   - 当 Follower 的状态机应用到对应的日志后，直接从本地读取数据并返回结果。

我认为当前etcd就实现的Follower read可能是更有效的一种一致性读的实现方式。读请求可以发给follower，follower先去leader查询最新的committed index，然后等待自身的committed index增长为读请求发生时的leader的committed index，从而保证能从follower中读到最新的数据。

## 安全性保障（核心）

Raft算法中引入了如下两条规则，来确保了

- **已经commit的消息，一定会存在于后续的Leader节点上，并且绝对不会在后续操作中被删除。**
- 对于并未commit的消息，可能会丢失。

**多数投票规则**

在上面投票环节也有介绍过，一个candidate必须获得集群中的多数投票，才能被选为Leader；而对于每条commit过的消息，它必须是被复制到了集群中的多数节点，也就是说成为Leader的节点，至少有1个包含了commit消息的节点给它投了票。

而在投票的过程中每个节点都会与candidate比较日志的最后index以及相应的term，如果要成为Leader，必须有更大的index或者更新的term，所以Leader上肯定有commit过的消息。



**提交规则**

上面说到，只要日志在多数结点上存在，那么 Leader 就可以提交该操作。但是**Raft额外限制了 Leader只对自己任期内的日志条目适用该规则，先前任期的条目只能由当前任期的提交而间接被提交。** 也就是说，当前任期的Leader，不会去负责之前term的日志提交，之前term的日志提交，只会随着当前term的日志提交而间接提交。



- 一个候选者在发起选举时，必须包含自己的日志中的最后一个条目的索引和任期。一个节点在投票给候选者时，必须检查候选者的日志是否比自己的日志更新。这样，可以保证选出的领导者的日志是最新的。
- 一个领导者在复制日志时，必须包含自己的日志中的最后一个条目的索引和任期。一个节点在接受日志时，必须检查领导者的日志是否与自己的日志匹配。这样，可以保证领导者的日志是一致的。
- 一个领导者在提交日志时，必须保证自己的任期与日志条目的任期相同。这样，可以保证领导者不会提交过期的日志条目。





看日志提交过程， 会不会刚本地提交，其它follower还没提交，但有日志，如何处理？

- 新Leader直接根据日志在多数节点存在的这个规则，会将之前term的日志提交

- 如果该日志已经在大多数节点上持久化，新的 Leader 会继续提交该日志。

  

![image-20211226173439780](https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20211226173439.png)



## 安全性保证总结

- 日志顺序写，保持最新，如果有不一致，会被leader的日志覆盖。
- 选举时只有最新日志的才能参与选举，防止旧的follower当选leader而导致丢信息。
- 已经commit的消息，一定会存在于后续的Leader节点上，并且绝对不会在后续操作中被删除。对于并未commit的消息，可能会丢失。
- 防止脑裂，Raft leader拥有最新的数据，因此读请求走leader那么leader可以直接返回结果给客户端，但直接从leader状态机读并不能完全确保系统的线性一致性。比如发生网络分区，旧leader处于少数派分区中，此时直接从旧leader的状态机读，则很可能返回过期的数据。所以leader需要在发起读时记录当前的committed Index，然后在后续heartbeat请求中如果能获得多数follower对leadership的确认，那么可以等待committed Index提交到状态机后即可返回结果。记录committed Index是因为当一个节点刚当选 Leader的时候并不知道最新的committed index。 





其它, [参考](https://www.modb.pro/db/429660) ：

因为复制流程无法完全保证数据一致，所以算法有有了一致性检查的部分，就是安全性组件的职责。一致性检查有几个基本原则，原文是这么表述的：

•对于一个给定的任期号，最多只会有一个Leader被选举出来（章节5.2)

•Leader绝对不会删除或者覆盖自己的日志，只会增加（章节5.3）

•如果两个日志在某一相同索引位置日志条目的任期号相同，那么我们就认为这两个日志从头到该索引位置之间的内容完全一致（章节5.3）

•如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（章节5.4）

•如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目（章节5.4.3）





这个表述说的有些抽象，我这里尝试简单解释和扩展一下，我说的不一定都很准确，读者以原论文表述为主：raft算法要求所有Follower与Leader保持强一致，换句话说，一致的数据保留，不一致的数据丢弃，替换成Leader的数据。只有Follower会主动丢弃数据，Leader永远不会主动丢弃数据。因为Leader是数据最新的节点（index值最大的节点才能获胜），故所有已提交（一半节点数以上）的Entry在Leader上面都有，强制Follower把缺少的数据补齐；对于Follower上已经提交的数据，Leader上一定存在；对于Follower上没有提交的数据，原则上可以直接遗弃（这里只是说“可以”，并不一定遗弃，如果和Leader上同index的数据冲突才会主动遗弃）。对于Leader上已提交的数据，毫无疑问保留；对于Leader上未提交的数据，通过AppendEntriesRpc的方式再逐步同步给所有Follower。



# Raft vs Paxos

共同点: 

- **服务器都会存储一个递增的数字叫做 Term（任期号），每条 RPC 消息都会包含 Term。当服务器接收到 RPC 时，它会检查 RPC 里包含的 Term 与自身 Term 的大小**
- 都有3种类型。 服务器最初都是 Candidate 状态，它们会尝试互相发送 RequestVote RPC  当选 Leader。有一台 Candidate 会成为 Leader，其他服务器会成为 Follower。当 Follower 认为 Leader 失败，又会成为 Candidate 进行选举。Leader 节点必须定期发送 AppendEntries RPC 作为 keepalive，以防止 Follower 超时成为 Candidate。



差异点: 

- **Paxos 允许任何服务器成为 Leader，然后再从其他服务器补齐缺少的日志，而 Raft 只允许拥有最新日志的服务器成为 Leader。**

- **在 Raft 中，日志条目的 term 不会被未来的 leader 所修改。而在 Paxos 协议下，这是可能的。**

  在 Raft 中，新的 Leader 选举出来后，对待上一个 term 未提交的日志条目，会继续沿用原有的 term，复制到其他节点。**事实上，Raft Leader 甚至永远不会覆盖或删除其日志中的条目，只会追加写新条目。**

- **Raft 的日志是严格顺序写入的，而 Paxos 通常允许无序写入，但需要额外的协议来填充可能因此发生的日志间隙。** 无序写入的优势是可以实现更高的并发性和性能。但是,这需要付出额外的复杂性代价来处理日志的不一致情况。相反，Raft 的严格顺序写入降低了这种复杂性，代价是牺牲一定的并发性。

- 在 Raft 协议里，即使日志条目被多数派的节点所接受（但未提交），也有可能被回滚掉。只有新选举出来的 Leader 将当前 term 的第一个日志条目写到多数派服务器上，上一个 term 的日志条目才可以安全提交。而在 Paxos 系统里，只要日志条目被复制到了多数派服务器上，Paxos 就可以安全地提交日志条目。



raft优势：简单，好懂，易实现。

RAFT的简单有好几个方面，比如：

1）协议上的简化（最后主要RPC只有两个，其他协议的二阶段、三阶段也都变成 /看起来像是一阶段）； 

2）TERM概念的强化（看起来似乎PAXOS也有重选LEADER的机制，但是强化概念，并增加一个TERM内有一个一个LEADER、ENTRY与TERM相关的属性等都大大简化了流程）；

3）LOG只会从LEADER到FOLLOWER单向同步（实现一下你会发现这真的减少好多问题，代码量都少了好多）；

