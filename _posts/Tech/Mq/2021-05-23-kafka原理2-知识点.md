---
layout: post
category: Mq
title: kafka原理2-知识点
tags: Mq
---

## kafka原理2-知识点

- kafka使用tcp, io多路复用即信号驱动io, 生产者有同步和异步2种类型

- 选择由producer向broker push消息并由consumer从broker pull消息。

- kafka和nsq对比： 
  
  - kafka是pull，有序，吞吐高；nsq消息是无序的，吞吐低，有requeue和defer功能，不持久化，不可回溯，pull，用内存，所以速度快。
  
- kafka数据可靠性和重复消费
  1. 需要消费者操作幂等，来保证重复消费无影响
  2. 处理后提交commit，保证消息被消费到，事务保证
  3. 生产者生产消息失败时，报error。
  4. 如果要保证有序，让消息到1个partition就行了，partition内部消费是有序的
  
- kafka基于zk. 

- kafka是发布-订阅模型。

- Zookeeper 主要为 Kafka 做了下面这些事情：

  1. **Broker 注册** ：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
  2. **Topic 注册** ： 在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
  3. **负载均衡** ：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。
  4. ......
  
- ISR:In-Sync Replicas 副本同步队列
  AR:Assigned Replicas 所有副本
  
  HW:High Watermark 高水位，取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置上一条信息。
  
  LEO:LogEndOffset 当前日志文件中下一条待写信息的offset
  
  HW/LEO这两个都是指最后一条的下一条的位置而不是指最后一条的位置。
  
  LSO:Last Stable Offset 对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同
  
  LW:Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值
  
  

## 面试题

- [kafka面试题](https://juejin.cn/post/6844903889003610119)
- [kafka面试题2](https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/distributed-system/message-queue/Kafka%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93.md)
- [整理，答案不全的](http://trumandu.github.io/2019/04/13/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98%E4%B8%8E%E7%AD%94%E6%A1%88%E5%85%A8%E5%A5%97%E6%95%B4%E7%90%86/)
- [面试题3](https://cloud.tencent.com/developer/article/1541215)

## 控制器Controller

- 控制器是如何被选出来的？

  - 你一定很想知道，控制器是如何被选出来的呢？我们刚刚在前面说过，每台 Broker 都能充当控制器，那么，当集群启动后，Kafka 怎么确认控制器位于哪台 Broker 呢？

    实际上，Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。

- 控制器是做什么的？

  - 1.主题管理（创建、删除、增加分区）

    2.分区重分配

    3.Preferred 领导者选举

    4.集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）

    5.数据服务

- 保存的数据：

- ![image-20210523170815843](https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20210523170815.png)





## consumer管理offset

**kafka内部有个主题，__consumer_offset**

老版本 Consumer 的位移管理是依托于 Apache ZooKeeper 的，它会自动或手动地将位移数据提交到 ZooKeeper 中保存。当 Consumer 重启后，它能自动从 ZooKeeper 中读取位移数据，从而在上次消费截止的地方继续消费。这种设计使得 Kafka Broker 不需要保存位移数据，减少了 Broker 端需要持有的状态空间，因而有利于实现高伸缩性。

但是，ZooKeeper 其实并不适用于这种高频的写操作，因此，Kafka 社区自 0.8.2.x 版本开始，就在酝酿修改这种设计，并最终在新版本 Consumer 中正式推出了全新的位移管理机制，自然也包括这个新的位移主题。

新版本 Consumer 的位移管理机制其实也很简单，就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。显然，Kafka 的主题设计天然就满足这两个条件，因此，使用 Kafka 主题来保存位移这件事情，实际上就是一个水到渠成的想法了。

位移主题的 Key 中应该保存 3 部分内容：gourpId, topic, partitionId