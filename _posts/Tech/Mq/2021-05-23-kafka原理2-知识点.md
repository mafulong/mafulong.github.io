---
layout: post
category: Mq
title: kafka原理2-知识点
tags: Mq
---

## kafka原理2-知识点

- kafka使用tcp, io多路复用即信号驱动io, 生产者有同步和异步2种类型
- 选择由producer向broker push消息并由consumer从broker pull消息。
- kafka和nsq对比： 
  - kafka是pull，有序，吞吐高；nsq消息是无序的，吞吐低，有requeue和defer功能，不持久化，不可回溯，pull，用内存，所以速度快。
- kafka数据可靠性和重复消费
  1. 需要消费者操作幂等，来保证重复消费无影响
  2. 处理后提交commit，保证消息被消费到，事务保证
  3. 生产者生产消息失败时，报error。
  4. 如果要保证有序，让消息到1个partition就行了，partition内部消费是有序的

- kafka基于zk. 

  

## 控制器Controller

- 控制器是如何被选出来的？

  - 你一定很想知道，控制器是如何被选出来的呢？我们刚刚在前面说过，每台 Broker 都能充当控制器，那么，当集群启动后，Kafka 怎么确认控制器位于哪台 Broker 呢？

    实际上，Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。

- 控制器是做什么的？

  - 1.主题管理（创建、删除、增加分区）

    2.分区重分配

    3.Preferred 领导者选举

    4.集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）

    5.数据服务

- 保存的数据：

- ![image-20210523170815843](https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20210523170815.png)





## consumer管理offset

**kafka内部有个主题，__consumer_offset**

老版本 Consumer 的位移管理是依托于 Apache ZooKeeper 的，它会自动或手动地将位移数据提交到 ZooKeeper 中保存。当 Consumer 重启后，它能自动从 ZooKeeper 中读取位移数据，从而在上次消费截止的地方继续消费。这种设计使得 Kafka Broker 不需要保存位移数据，减少了 Broker 端需要持有的状态空间，因而有利于实现高伸缩性。

但是，ZooKeeper 其实并不适用于这种高频的写操作，因此，Kafka 社区自 0.8.2.x 版本开始，就在酝酿修改这种设计，并最终在新版本 Consumer 中正式推出了全新的位移管理机制，自然也包括这个新的位移主题。

新版本 Consumer 的位移管理机制其实也很简单，就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。显然，Kafka 的主题设计天然就满足这两个条件，因此，使用 Kafka 主题来保存位移这件事情，实际上就是一个水到渠成的想法了。

位移主题的 Key 中应该保存 3 部分内容：gourpId, topic, partitionId