---
layout: post
category: SystemDesign
title: 限流器
tags: SystemDesign
---

保障服务稳定的三大利器：熔断降级、服务限流和故障模拟。今天和大家谈谈限流算法的几种实现方式，本文所说的限流并非是Nginx层面的限流，而是业务代码中的逻辑限流。

## 为什么需要限流

按照服务的调用方，可以分为以下几种类型服务

### 1、与用户打交道的服务

比如web服务、对外API，这种类型的服务有以下几种可能导致机器被拖垮：

- 用户增长过快（这是好事）
- 因为某个热点事件（微博热搜）
- 竞争对象爬虫
- 恶意的刷单

这些情况都是无法预知的，不知道什么时候会有10倍甚至20倍的流量打进来，如果真碰上这种情况，扩容是根本来不及的（弹性扩容都是虚谈，一秒钟你给我扩一下试试）

### 2、对内的RPC服务

一个服务A的接口可能被BCDE多个服务进行调用，在B服务发生突发流量时，直接把A服务给调用挂了，导致A服务对CDE也无法提供服务。 这种情况时有发生，解决方案有两种： 1、每个调用方采用线程池进行资源隔离 2、使用限流手段对每个调用方进行限流



## 服务限流：

流量控制本质上是减小访问量，而服务处理能力不变；而服务降级本质上是降低了部分服务的处理能力，增强另一部分服务处理能力，而访问量不变。

以下主要介绍几种常见的服务限流算法和优缺点，以及单机限流和分布式限流。没有哪种算法是最好的或者是最差的，具体要根据实际业务场景决定使用哪种实现方式，本质都是提高功能的性价比，利用尽可能小的开发成本，产生尽可能大的收益。常见的限流算法包含：计数器法，滑动窗口算法，令牌桶算法以及漏桶算法（队列限流）。

### 计数器法

计数器法是限流算法里最简单也是最容易实现的一种算法。假设我们规定接口A的qps是100， 即每分钟的访问次数不能超过100。那么我们可以这么做：在一开始的时候，我们可以设置一个计数器counter，初始化为0， 过期时间为1秒，即1秒后计数器失效。每当一个请求过来的时候，counter值加1，判断当前counter的值是否大于100，如果大于100则说明请求数过多，直接拒绝请求。如果请求counter计数器不存在，则重置计数器，开始新的一秒的接口限流。注意并发情况下访问计数器需要加锁。

缺点：限制粒度太低，存在临界问题。

例如：假设有一个恶意用户，他在0:59时，瞬间发送了100个请求，并且1:00又瞬间发送了100个请求，那么其实这个用户在1秒内，瞬间发送了200个请求。用户通过在时间窗口的重置节点处突发请求，可以瞬间超过我们的速率限制。用户有可能通过算法的这个漏洞，瞬间压垮我们的应用。解决这个问题的办法就是提高限流的粒度，即滑动窗口算法。

### 滑动窗口（rolling window）

滑动窗口的概念源于计算机网络，它的限流思想描述如下：假设一个时间窗口就是一分钟。然后我们将时间窗口进行划分，比如我们将滑动窗口划成了6格，所以每格代表的是10秒钟。每过10秒钟，我们的时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求在0:35秒的时候到达，那么0:30~0:39对应的counter就会加1。滑动窗口能够很好的解决计数器法所存在的临界问题，并且窗口划分粒度越细，窗口滑动就越平滑，控制效果越好。滑动窗口实现较复杂，临界问题只是某种极端案例，比如恶意攻击，是否采用这种限流方式，还需取决于具体业务的要求。

### 漏桶算法

为了消除”突刺现象”，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。

不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。

在算法实现方面，可以准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。

这种算法，在使用过后也存在弊端：无法应对短时间的突发流量。这个指和令牌桶比较而言，突发指令牌桶可以每秒100qps的条件下，支持每10ms支持100qps， 而漏桶只能每10ms支持1qps，可以理解为漏桶只能平均。

### 令牌桶法

从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。

思想描述：系统按照恒定的时间间隔（通常是1/QPS）往桶里加入Token,每个Token代表一次接口访问权限，如果桶已经满了丢弃令牌。新请求来临时，会请求从桶中拿走一个Token,如果没有Token可拿了就阻塞或者拒绝服务请求。放入Token的时间间隔取决于限制的qps，假设接口的qps是100，则按照1/qps的速率放令牌，即每10ms放入一个令牌，令牌桶算法不存在瞬间的流量高峰，它能严格控制接口在qps内访问。

![img](https://cdn.jsdelivr.net/gh/mafulong/mdPic@vv3/v3/20210412173956)



放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。

实现思路：可以准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行。

### 单机限流器使用场景

#### 两种算法的区别

​	两者主要区别在于“漏桶算法”能够强行限制数据的传输速率，而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，所以它适合于具有突发特性的流量。

​	对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。令牌桶也是最适用的。

​	并不能说明令牌桶一定比漏洞好，她们使用场景不一样。令牌桶可以用来保护自己，主要用来对调用者频率进行限流，为的是让自己不被打垮。所以如果自己本身有处理能力的时候，如果流量突发（实际消费能力强于配置的流量限制），那么实际处理速率可以超过配置的限制。而漏桶算法，这是用来保护他人，也就是保护他所调用的系统。主要场景是，当调用的第三方系统本身没有保护机制，或者有流量限制的时候，我们的调用速度不能超过他的限制，由于我们不能更改第三方系统，所以只有在主调方控制。这个时候，即使流量突发，也必须舍弃。因为消费能力是第三方决定的。

​	总结起来：如果要让自己的系统不被打垮，用令牌桶。如果保证被别人的系统不被打垮，用漏桶算法。

## 集群式限流

相比上面的单机限流，也可以分布式集群限流。

需要额外的存储，比如redis等。



## 限流器实现

### golang实现令牌桶

- 初始化qps上线limit, 间隔时间internal（单位ms)

- 使用int32当做桶的数量，token，操作使用atomic.LoadInt32, AddInt32进行操作，防止并发问题。性能足够好: [性能参考](https://m.51dev.com/show.php?id=84890)
- 使用time.Ticker每隔internal ms，原子操作token+=1。实际上是个定时任务。
- 判断能否限流规则， token>0则不限流，原子判断token是否大于0



### golang实现令牌桶 + 阻塞FIFO

- 用channel是不好实现FIFO的， 尤其是qps每次取的1个而是多个时，用channel取出来就没法还回去了。只能获取qps时不停轮训看满没满足。
- 另一种更合理的方式是定时任务，每次获取qps不够时就按时间扣减成负数。然后定时器来唤醒。这样后续获取qps都在之前基础上继续扣减、算一个时间来唤醒当前goroutine。 

[参考](https://www.cyhone.com/articles/analisys-of-golang-rate/)

### golang实现漏桶

略

### 分布式限流器

要求非单机，因此可以使用redis实现，

redis kv, v是当前访问数，可以通过lua脚本保证原子性。这是限制访问量的做法。不是限流限制qps。使用时+1,用完-1。



如果是限制qps，可以利用redis做令牌桶，一个线程每秒添加令牌，每次使用都取1个，用完也不会归还，用lua脚本保证原子性。

如果不想用单独线程每秒添加令牌，可以记录上次的访问时间，然后访问时和上次访问时间diff，看应该增加多少令牌。



